
<!DOCTYPE html>
<html>

	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width initial-scale=1">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<title>Foundation Models for Educational Assessment | Workshop 2024</title>
		<meta name="description" content="A venue for Foundation Models for Educational Assessment
">
		<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/2/24/DCT-8x8.png">
		<link rel="shortcut icon" href="https://neuralcompression.github.io/assets/img/favicon.ico">
		<link rel="stylesheet" href="main.css">
		<link rel="canonical" href="https://neuralcompression.github.io/workshop23">
		<link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/base-min.css">
	</head>

	<body>
		<header class="site-header">
			<div class="wrapper"> <a href=""> <span class="site-title">
						<!--<strong>Foundation Models for Educational Assessment</strong>-->FM-EduAssess </span> </a> <nav class="site-nav"> <input type="checkbox" id="nav-trigger" class="nav-trigger"> <label for="nav-trigger"> <span class="menu-icon"> <svg viewBox="0 0 18 15" width="18px" height="15px"> <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
								<path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
								<path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path> </svg> </span> </label> <div class="trigger">
						<!-- <a class="page-link" href="https://neuralcompression.github.io/workshop23">Workshop 2024</a> <a class="page-link" href="https://neuralcompression.github.io/workshop21">Workshop 2021</a> <a class="page-link" href="https://neuralcompression.github.io/tutorial">Tutorial</a>  -->
						 <!-- <a class="page-link" href="https://neuralcompression.github.io/assets/pdf/CV.pdf">vitae</a> -->
					</div>
				</nav>
			</div>
			<meta name="robots" content="noindex">
		</header>
		<div class="page-content">
			<div class="header-background">
				<div class="img">
				</div>

				<div class="text">
				    <h2 style="color: white;">FM-EduAssess Workshop @NeurIPS 2024</h2>
				</div>

			</div>
			<div class="wrapper">
				<div class="post">
					<header class="post-header">
						<h1 class="post-title">Large Foundation Models for Educational Assessment</h1>
						<h3 class="post-description"><strong>Date:</strong> Dec 15 <br> <strong>Location:</strong> MTG 19&20</h3>
						<!-- <h5 class="post-description">Workshop @NeurIPS 2024</h5> -->
					</header>
					<article class="post-content Workshop 2024 clearfix">
						<!-- <h3 id="NeurIPS-page-with-recordingslides-httpsNeurIPSccvirtual2024workshop21499">NeurIPS page with recording/slides: <a href="">to do</a></h3> -->
						<!-- <h3 id="accepted-papers-openreview">Accepted papers: <a href="https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/NCW">to do</a></h3> -->
						
    <p>The advanced generative artificial intelligence (AI) techniques, such as large language models and large multimodal models, are transforming many aspects of educational assessment. The integration of AI into education has the potential to revolutionize not only test development and evaluation but also the way students can learn. Over the past years, some successful adoptions of machine learning in this area are using natural language processing for automated scoring, or applying collaborative filtering to predict student responses. The rapid advances of large foundation models (e.g., ChatGPT, GPT-4, Llama, Gemini) demonstrate the potential of intelligent assessment with data-driven AI systems. These models could potentially benefit test construct identification, automatic item generation, multimodal item design, automated scoring, and assessment administration. Meanwhile, new research challenges arise in the intersection of AI and educational assessments. For instance, the explainability and accountability of current large foundations models are still inadequate to convince the stakeholders in the educational ecosystem, which limits the adoption of AI techniques in large-scale assessments. Also, it is still unclear whether the large foundation models are capable of assisting complex assessment tasks that involve creative thinking or high-order reasoning. Tackling these research challenges would require collaborative efforts from researchers and practitioners in both AI and educational assessment.</p>
    <p>This one-day workshop provides a forum for researchers from AI and educational assessment to review and discuss the recent advances of applying large foundation models for educational assessment. The workshop includes up to five keynote talks and up to 12 peer-reviewed papers (oral and poster). Original high-quality contributions are solicited on the following topics:</p>
    <ul>
        <li>Large foundation models for automated scoring</li>
        <li>Large foundation models for automated item generation</li>
        <li>Large foundation models for computerized adaptive testing</li>
        <li>Large foundation models for educational content generation</li>
        <li>Large foundation models for knowledge tracing</li>
        <li>Large foundation models for creating technology-enhanced items</li>
        <li>Knowledge augmentation of large models for educational assessment</li>
        <li>Knowledge editing of large models for educational assessment</li>
        <li>Finetune large foundation models for educational assessment</li>
        <li>Generative AI for assessment security and accountability</li>
        <li>Trustworthy AI (Fairness, Explainability, Privacy) for educational assessment</li>
    </ul>




						<h3 id="awards">Call for Papers</h3>



						<p><span style="font-weight: 600;">Submission URL:</span>  <a href="https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/FM-EduAssess">Openreview</a></p>

						<p><span style="font-weight: 600;">Format:</span>  All submissions must be in PDF format and anonymized. Submissions are limited to nine content pages, including all figures and tables; unlimited additional pages containing references and supplementary materials are allowed. Reviewers may choose to read the supplementary materials but will not be required to. </p>

						<p><span style="font-weight: 600;">Style file:</span>  You must format your submission using the NeurIPS 2024 LaTeX style file. The maximum file size for submissions is 50MB. Submissions that violate the NeurIPS style (e.g., by decreasing margins or font sizes) or page limits may be rejected without further review. </p>

						<p><span style="font-weight: 600;">Double-blind reviewing: </span>  The reviewing process will be double blind at the level of reviewers (i.e., reviewers cannot see author identities). Authors are responsible for anonymizing their submissions. In particular, they should not include author names, author affiliations, or acknowledgements in their submissions and they should avoid providing any other identifying information (even in the supplementary material). </p>

						<i>The workshop is non-archival, so you can have a concurrent submission of your work to both the workshop and and other venues.</i>

					<!-- 	<p><strong>Oral presentations</strong></p>
						<p><a href="https://openreview.net/forum?id=3Dq4FZJSga"><em>Neural Distributed Compressor Does Binning.</em></a> Ezgi Ozyilkan, Johannes Ball√©, Elza Erkip</p>
						<p><a href="https://openreview.net/forum?id=PggJ9CbEN7"><em>Entropy Coding of Unordered Data Structures.</em></a> Julius Kunze, Daniel Severo, Giulio Zani, Jan-Willem van de Meent, James Townsend</p>
						<p><a href="https://openreview.net/forum?id=IXLfVFeI5a"><em>Neural Image Compression: Generalization, Robustness, and Spectral Bias.</em></a> Kelsey Lieberman, James Diffenderfer, Charles Godfrey, Bhavya Kailkhura</p>
						<p><a href="https://openreview.net/forum?id=cbLcwK3SZi"><em>Slicing Mutual Information Generalization Bounds for Neural Networks.</em></a> Kimia Nadjahi, Kristjan Greenewald, Rickard Br√ºel Gabrielsson, Justin Solomon üèÜ <span style="color:red">Best paper award</span>üèÜ</p>
						<p><strong>Spotlight presentations</strong></p>
						<p><a href="https://openreview.net/forum?id=5pt5Btjr8W"><em>Estimating the Rate-Distortion Function by Wasserstein Gradient Descent.</em></a> Yibo Yang, Stephan Eckstein, Marcel Nutz, Stephan Mandt</p>
						<p><a href="https://openreview.net/forum?id=GDIp6mRu5m"><em>Lossy Image Compression with Conditional Diffusion Model.</em></a> Ruihan Yang, Stephan Mandt</p>
						<p><a href="https://openreview.net/forum?id=5VgMDKUgX0"><em>NNCodec: An Open Source Software Implementation of the Neural Network Coding ISO/IEC Standard.</em></a> Daniel Becking, Paul Haase, Heiner Kirchhoffer, Karsten M√ºller, Wojciech Samek, Detlev Marpe</p>
						<p><a href="https://openreview.net/forum?id=YhIvfWIdqJ"><em>On the Choice of Perception Loss Function for Learned Video Compression.</em></a> Buu Phan, Sadaf Salehkalaibar, Jun Chen, Wei Yu, Ashish J Khisti</p>
						<p><a href="https://openreview.net/forum?id=38sgR7agFC"><em>Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations.</em></a> Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen</p> -->






						<!-- <h3 id="awards">Awards</h3> -->
					<!-- 	<p><strong>Oral presentations</strong></p>
						<p><a href="https://openreview.net/forum?id=3Dq4FZJSga"><em>Neural Distributed Compressor Does Binning.</em></a> Ezgi Ozyilkan, Johannes Ball√©, Elza Erkip</p>
						<p><a href="https://openreview.net/forum?id=PggJ9CbEN7"><em>Entropy Coding of Unordered Data Structures.</em></a> Julius Kunze, Daniel Severo, Giulio Zani, Jan-Willem van de Meent, James Townsend</p>
						<p><a href="https://openreview.net/forum?id=IXLfVFeI5a"><em>Neural Image Compression: Generalization, Robustness, and Spectral Bias.</em></a> Kelsey Lieberman, James Diffenderfer, Charles Godfrey, Bhavya Kailkhura</p>
						<p><a href="https://openreview.net/forum?id=cbLcwK3SZi"><em>Slicing Mutual Information Generalization Bounds for Neural Networks.</em></a> Kimia Nadjahi, Kristjan Greenewald, Rickard Br√ºel Gabrielsson, Justin Solomon üèÜ <span style="color:red">Best paper award</span>üèÜ</p>
						<p><strong>Spotlight presentations</strong></p>
						<p><a href="https://openreview.net/forum?id=5pt5Btjr8W"><em>Estimating the Rate-Distortion Function by Wasserstein Gradient Descent.</em></a> Yibo Yang, Stephan Eckstein, Marcel Nutz, Stephan Mandt</p>
						<p><a href="https://openreview.net/forum?id=GDIp6mRu5m"><em>Lossy Image Compression with Conditional Diffusion Model.</em></a> Ruihan Yang, Stephan Mandt</p>
						<p><a href="https://openreview.net/forum?id=5VgMDKUgX0"><em>NNCodec: An Open Source Software Implementation of the Neural Network Coding ISO/IEC Standard.</em></a> Daniel Becking, Paul Haase, Heiner Kirchhoffer, Karsten M√ºller, Wojciech Samek, Detlev Marpe</p>
						<p><a href="https://openreview.net/forum?id=YhIvfWIdqJ"><em>On the Choice of Perception Loss Function for Learned Video Compression.</em></a> Buu Phan, Sadaf Salehkalaibar, Jun Chen, Wei Yu, Ashish J Khisti</p>
						<p><a href="https://openreview.net/forum?id=38sgR7agFC"><em>Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations.</em></a> Yang Sui, Zhuohang Li, Ding Ding, Xiang Pan, Xiaozhong Xu, Shan Liu, Zhenzhong Chen</p> -->








<!-- 						<h3 id="call-for-papers">Call for Papers</h3>
						<p>The workshop solicits original research on the topic of learning-based approaches to data compression and communication.</p>
						<p>The ubiquity of communication technology has made efficient and effective data compression an increasingly critical research area. Recent work building on deep generative models such as variational autoencoders, GANs, normalizing flows, and diffusion models has shown that machine-learning-based compression methods can significantly outperform state-of-the-art classical compression codecs for image and video data. However, there are still open questions and practical problems holding back these methods from making a major impact in real-world applications.</p>
						<p>This workshop aims to address these issues by bringing together researchers from diverse fields including deep generative modeling, information theory, and statistics (Bayesian or otherwise). We believe that a multi-disciplinary approach to compression will lead to new synergies and result in a new generation of learnable codecs, as well as a better understanding of theoretical aspects.</p>
						<p>Topics of interest include, but are not limited to,</p>
						<ul>
							<li>Data compression (e.g., images, video, audio) with machine learning</li>
							<li>Probabilistic modeling and inference for compression</li>
							<li>Quantization, entropy coding, and stochastic coding</li>
							<li>Theoretic understanding of learned compression</li>
							<li>Fundamental performance bounds/limits</li>
							<li>Learning-based approaches to information theory</li>
							<li>Computationally-efficient models/methods</li>
							<li>Perceptual metrics and image quality assessment algorithms</li>
						</ul>
 -->






						<!--
### Call for Reviewers
Please fill out this [Google form](https://docs.google.com/forms/d/e/1FAIpQLSd3L9_o7vAZUSWjWMxi18jZHuIrBaafUBm6v1fTZQorK2o9Qw/viewform) if you are interested in reviewing for the workshop.

~~üèÜ **2 free NeurIPS 2024 workshop registrations will be given as "Best Reviewer Awards"** üèÜ~~

						<h3 id="important-dates">Important Dates</h3>
						<ul>
							<li><del><strong>Submission deadline</strong>: May 27 11:59 PM AOE (anywhere on earth), 2024</del></li>
							<li><del><strong>Notification date</strong>: June 19, 2024</del></li>
							<li><del><strong>Workshop date</strong>: 9 AM - 5 PM Hawaii time (HST), July 29, 2024</del></li>
						</ul>
						<h3 id="submission-instructions">Submission Instructions</h3>
						<p><strong>Submission website: <a href="https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/NCW">OpenReview</a></strong></p>
						<p>We solicit short workshop paper submissions of up to 4 pages + unlimited references/appendices. Please format submissions in NeurIPS style. Submissions will be double blind: reviewers cannot see author names when conducting reviews, and authors cannot see reviewer names.</p>
						<p>Some accepted papers will be accepted as contributed talks. All accepted posters are expected to be presented in-person at the poster session, and all papers published via Openreview after the workshop.</p>
						<p>This workshop will not have formal proceedings, so we welcome the submission of work currently under review at other archival ML venues. We also welcome the submission of work recently published in information theory venues (e.g. Transactions on Information Theory, ISIT, ITW) that may be of interest to an ML audience. However, we will not consider work recently published in or accepted to other archival ML venues (e.g. NeurIPS main conference).</p> <!-- Paper submissions should be made through OpenReview and further information will be available at [CFP](/cfp/). Please send your inquiries by email to the organizers at [neural.compression.workshop@gmail.com](mailto:neural.compression.workshop@gmail.com). -->


						<h3 id="awards">Key Dates</h3>
						<ul>
						    <li>Submission Deadline: <span style="font-weight: 500;">Aug 30, 2024</span></li>
						    <li>Notification: <span style="font-weight: 500;">Oct 9, 2024</span></li>
						    <li>Camera-ready Deadline: <span style="font-weight: 500;">Oct 30, 2024</span></li>
						    <li>Event: <span style="font-weight: 500;">Dec 15, 2024 (Location: MTG 19&20)</span></li>
						</ul>


						<h3 id="speakers">Speakers</h3>
						<table style="width:70%">
							<tbody>
								<tr>
									<td style="text-align:center; border: 1;"><img src="images/wang.jpg" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/jiao.webp" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/yang.jpg" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/lottridge.jpg" height="175"></td>
								</tr>
								<tr>
									<td style="text-align:center; border: 1;"><a href="">Hongning Wang</a> <br> Tsinghua University </td>
									<td style="text-align:center; border: 1;"><a href="">Hong Jiao</a> <br> University of Maryland </td>
									<td style="text-align:center; border: 1;"><a href="">Diyi Yang</a> <br> Stanford </td>
									<td style="text-align:center; border: 1;"><a href="">Susan Lottridge</a> <br> Cambium Assessment </td>
								</tr>
<!-- 								<tr>
									<td style="text-align:center"><img src="assets/img/aaron_wagner.jpg" height="175"></td>
									<td style="text-align:center"><img src="assets/img/tsachy_weissman.png" height="175"></td>
								</tr>
								<tr>
									<td style="text-align:center"><a href="https://www.ece.cornell.edu/faculty-directory/aaron-b-wagner">Aaron Wagner</a> <br> Professor, Cornell</td>
									<td style="text-align:center"><a href="https://web.stanford.edu/~tsachy/">Tsachy Weissman</a> <br> Professor, Stanford</td>
								</tr> -->
							</tbody>
						</table>


						<h3 id="speakers">Given Talks</h3>
<!-- 						<table style="width:100%; border-collapse: collapse; border: 1px solid #ddd; font-family: Arial, sans-serif;">
						    <thead>
						        <tr style="background-color: #f2f2f2;">
						            <th style="text-align:center; padding: 12px; border: 1px solid #ddd;">Speaker</th>
						            <th style="text-align:center; padding: 12px; border: 1px solid #ddd;">Title</th>
						            <th style="text-align:center; padding: 12px; border: 1px solid #ddd;">Introduction</th>
						        </tr>
						    </thead>
						    <tbody>
						        <tr>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">Hongning Wang</td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">The practices and lessons learnt from AI-assisted teaching in Tsinghua </td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">To promote deep integration of artificial intelligence (AI) technology with education, Tsinghua University launched a university-wide initiative named ‚ÄòAI-Enabled Teaching Pilot Program' in the fall 2023. The program actively invests on the research and development of AI teaching assistants based on the latest generative AI technologies, tailored to specific needs of individual courses. To date, the developed AI teaching assistants have been introduced into more than 150 courses‚Äô daily teaching practices, and received very positive feedback from both students and instructors. This initiative provides a valuable experimental platform for AI and educational researchers to closely observe and analyze the profound impact of GenAI technology on education and teaching. It also lays the groundwork and provides experience for the subsequent larger-scale development of both the AI-assisted educational systems and the courses themselves. In this presentation, we will showcase the primary functions of the intelligent teaching assistant systems and share our observations and reflections on the potential impacts of AI technology on the field of education. </td>
						        </tr>
						        <tr style="background-color: #f9f9f9;">
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">Hong Jiao</td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">Coming soon</td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">  </td>
						        </tr>
						        <tr>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">Diyi Yang</td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">Coming soon</td>
						            <td style="text-align:center; padding: 12px; border: 1px solid #ddd;">  </td>
						        </tr>
						    </tbody>
						</table> -->

							<p> 
								<strong>The Practices and Lessons Learnt from AI-assisted Teaching in Tsinghua</strong>, <i> Hongning Wang </i>
	<!-- 							<br>
								<i> Hongning Wang </i> -->
								<br>
								To promote deep integration of artificial intelligence (AI) technology with education, Tsinghua University launched a university-wide initiative named ‚ÄòAI-Enabled Teaching Pilot Program' in the fall 2023. The program actively invests on the research and development of AI teaching assistants based on the latest generative AI technologies, tailored to specific needs of individual courses. To date, the developed AI teaching assistants have been introduced into more than 150 courses‚Äô daily teaching practices, and received very positive feedback from both students and instructors. This initiative provides a valuable experimental platform for AI and educational researchers to closely observe and analyze the profound impact of GenAI technology on education and teaching. It also lays the groundwork and provides experience for the subsequent larger-scale development of both the AI-assisted educational systems and the courses themselves. In this presentation, we will showcase the primary functions of the intelligent teaching assistant systems and share our observations and reflections on the potential impacts of AI technology on the field of education. 
							</p>

<!-- 						<h3 id="panelists">Panelists</h3>
						<table style="width:75%">
							<tbody>
								<tr>
									<td style="text-align:center"><img src="assets/img/ashish_khisti.jpg" height="175"></td>
									<td style="text-align:center"><img src="assets/img/ties_van_rozendaal.jpg" height="175"></td>
									<td style="text-align:center"><img src="assets/img/george_toderici.jpg" height="175"></td>
									<td style="text-align:center"><img src="assets/img/rashmi_vinayak.jpg" height="175"></td>
								</tr>
								<tr>
									<td style="text-align:center"><a href="https://www.ece.utoronto.ca/people/khisti-a/">Ashish Khisti</a> <br> Professor, University of Toronto</td>
									<td style="text-align:center"><a href="http://www.tivaro.nl/">Ties van Rozendaal</a> <br> Senior Deep Learning Researcher, Qualcomm</td>
									<td style="text-align:center"><a href="https://research.google/people/author38233/"> George Toderici </a> <br> Senior Staff Research Scientist, Google</td>
									<td style="text-align:center"><a href="http://www.cs.cmu.edu/~rvinayak/">Rashmi Vinayak</a> <br>Assistant Professor, CMU</td>
								</tr>
							</tbody>
						</table> -->
						<h3 id="organizers">Organizers</h3>
						<table style="width:100%">
							<tbody>
								<tr>
									<td style="text-align:center; border: 1;"><img src="images/shengli.png" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/c.jpg" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/lu.jpeg" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/de.jpg" height="175"></td>
								</tr>
								<tr>
<!-- 								<td style="text-align:center"><a href="">Sheng Li</a> <br>Associate Professor, University of Virginia</td>
									<td style="text-align:center"><a href="">Zhongmin Cui</a> <br> Senior Director/Senior Psychometrician, CFA Institute</td>
									<td style="text-align:center"><a href="">Jiasen Lu</a> <br> Research Scientist, Apple Inc.</td>
									<td style="text-align:center"><a href="">Deborah Harris</a> <br>Visiting Professor, University of Iowa</td> -->
									<td style="text-align:center; border: 1;"><a href="">Sheng Li</a> <br>University of Virginia</td>
									<td style="text-align:center; border: 1;"><a href="">Zhongmin Cui</a> <br>CFA Institute</td>
									<td style="text-align:center; border: 1;"><a href="">Jiasen Lu</a> <br>Apple Inc.</td>
									<td style="text-align:center; border: 1;"><a href="">Deborah Harris</a> <br>University of Iowa</td>
								</tr>
								<tr>
									<!-- <td style="text-align:center"><img src="images/shu.jpeg" height="175"></td> -->
									<!-- <td style="text-align:center"><img src="https://api.dsi.virginia.edu/sites/default/files/styles/square_sm/public/2023-09/PhD25%20Dongliang%20Guo%20FINAL.jpg?w=1500" height="175"></td> -->
									<td style="text-align:center; border: 1;"><img src="images/guo.jpg" height="175"></td>
									<td style="text-align:center; border: 1;"><img src="images/dqi.jpg" height="175"></td>
								</tr>
								<tr>
							<!-- 		<td style="text-align:center"><a href="=">Shumin Jing</a> <br> Psychometrician, Smarter Balanced</td>
									<td style="text-align:center"><a href="=">Dongliang Guo</a> <br> University of Virginia</td>
									<td style="text-align:center"><a href="https://daiqingq.github.io"> Daiqing Qi </a> <br>University of Virginia</td> -->
									<!-- <td style="text-align:center"><a href="=">Shumin Jing</a> <br> Smarter Balanced</td> -->
									<td style="text-align:center; border: 1;"><a href="=">Dongliang Guo</a> <br> University of Virginia</td>
									<td style="text-align:center; border: 1;"><a href="https://daiqingq.github.io"> Daiqing Qi </a> <br>University of Virginia</td>
								</tr>
							</tbody>
						</table>

							<h3 id="organizers-affiliations">Organizers Affiliations</h3>
							<img src="images/uva.jpeg" height="100" style="margin-right: 20px;"> 
							<img src="images/apple.png" height="100" style="margin-right: 20px;">
							<img src="images/iowa.png" height="100" style="margin-right: 20px;"> 
							<!-- <img src="images/sm.jpeg" height="100" style="margin-right: 20px;"> -->
							<img src="images/CFA_Institute_Logo_RGB.png" height="100">


						  </article>


					<!-- <div class="social"> <span class="contacticon center"> <a href="mailto:neural.compression.workshop@gmail.com"><i class="fas fa-envelope"></i></a> <a href="https://github.com/neuralcompression" target="_blank" title="GitHub"><i class="fab fa-github"></i></a> <a href="https://twitter.com/neural_compress" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a> </span> <div class="col three caption"> Follow us on Twitter for the latest updates! </div> -->
					</div>
				</div>
			</div>
		</div>
		<footer>
			<div class="wrapper"> ¬© Copyright 2024 Foundation Models for Educational Assessment. Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>. </div>
		</footer> <!-- Load jQuery -->
		<script async="" src="//www.google-analytics.com/analytics.js"></script>
		<script src="//code.jquery.com/jquery-1.12.4.min.js"></script> <!-- Load Common JS -->
		<script src="https://neuralcompression.github.io/assets/js/common.js"></script> <!-- Load KaTeX -->
		<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
		<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
		<script src="https://neuralcompression.github.io/assets/js/katex.js"></script> <!-- Include custom icon fonts -->
		<link rel="stylesheet" href="https://neuralcompression.github.io/assets/css/fontawesome-all.min.css">
		<link rel="stylesheet" href="https://neuralcompression.github.io/assets/css/academicons.min.css">
		<!-- Google Analytics -->
		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
			
			ga('create', 'UA-XXXXXXXXX', 'auto');
			ga('send', 'pageview');
		</script>
	</body>

</html>